{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import urllib.request, json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def api_request(stations, subscription_key):\n",
    "    '''This function makes an API request from the NS server and returns\n",
    "     the trajectories of the Dutch railway map.\n",
    "\n",
    "     Args:\n",
    "        stations (str): Two stations of which you want the trajectory in the form 'Station1,Station2'\n",
    "        subscription_key (str): An subscribtion key \n",
    "\n",
    "    Returns:\n",
    "        gdf (GeoDataFrame): GeoDataFrame with lines between stations\n",
    "    '''\n",
    "    \n",
    "    url = f\"https://gateway.apiportal.ns.nl/Spoorkaart-API/api/v1/traject.geojson?stations={stations}\"\n",
    "    headers = {\n",
    "        'Cache-Control': 'no-cache',\n",
    "        'Ocp-Apim-Subscription-Key': subscription_key,\n",
    "    }\n",
    "\n",
    "    # Make the API request\n",
    "    try:\n",
    "        req = urllib.request.Request(url, headers=headers)\n",
    "        response = urllib.request.urlopen(req)\n",
    "        response_content = response.read().decode('utf-8')\n",
    "\n",
    "        # Load the response content into JSON\n",
    "        geojson_data = json.loads(response_content)\n",
    "\n",
    "        # Convert the GeoJSON data to a GeoDataFrame\n",
    "        gdf = gpd.GeoDataFrame.from_features(geojson_data['features'])\n",
    "\n",
    "        return gdf\n",
    "    except urllib.error.HTTPError as e:\n",
    "        print(f\"HTTPError: {e.code} - {e.reason}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def travel_data(operators, seats_per_vehicle_type):\n",
    "    '''Taking a list of operators and a dictionary with the amount of seats per vehicle type.\n",
    "    Then by way of this list of operators importing their train schedules and using the dictionary\n",
    "    to assign the amount of seats each service in the schedule has.\n",
    "    \n",
    "    Args:\n",
    "        operators (List): List with operators you want to have in the final DataFrame\n",
    "        seats_per_vehicle_type (Dict): Dictionary with all train types with corresponding seat amounts per coach\n",
    "    \n",
    "    Returns:\n",
    "        travel_data (DataFrame): Dataframe with number of seats per train per trajectory\n",
    "    '''\n",
    "    # Selecting which operators you want in the final DataFrame\n",
    "    # First, the csv-document corresponding to the operator is made into a DataFrame\n",
    "    # Then, this DataFrame is concatenated to the other DataFrames\n",
    "\n",
    "    # Each DataFrame consist of multiple interesting columns:\n",
    "    # 1. 'OperatingDay' = Which day the train has driven\n",
    "    # 2. 'JourneyNumber' = This number corresponds to the route of the train (see Trainservices.csv)\n",
    "    # 3. 'UserStopCodeBegin' = This is the begin station of the trajectory\n",
    "    # 4. 'UserStopCodeEnd' = This is the end station of the trajectory\n",
    "    # 5. 'VehicleType' = Which train type is used on this trajectory\n",
    "    # 6. 'TotalNumberOfCoaches' = Number of coaches of this train on this trajectory\n",
    "    travel_data = pd.DataFrame()\n",
    "    for i in operators:\n",
    "        if i == 'Keolis':\n",
    "            keolis = pd.read_csv('Keolis.csv', delimiter= ';')\n",
    "            travel_data = pd.concat([travel_data, keolis], ignore_index=True)\n",
    "        elif i == 'Arriva':\n",
    "            arriva = pd.read_csv('Arriva.csv')\n",
    "            # For train type WINK, the cells are empty, so these are filled with 1's\n",
    "            arriva['TotalNumberOfCoaches'] = arriva['TotalNumberOfCoaches'].fillna(1)\n",
    "            travel_data = pd.concat([travel_data, arriva], ignore_index=True)\n",
    "        elif i == 'Qbuzz':\n",
    "            qbuzz = pd.read_csv('Qbuzz.csv')\n",
    "            travel_data = pd.concat([travel_data, qbuzz], ignore_index=True)\n",
    "        elif i == 'NS':\n",
    "            ns = pd.read_csv('OC_NS_20241007.csv')\n",
    "            travel_data = pd.concat([travel_data, ns], ignore_index=True)\n",
    "        else:\n",
    "            return print(\"Operator not known, known operators: [Keolis, Arriva, NS, Qbuzz]\")\n",
    "    \n",
    "    # Make an extra column where the seats will be stored\n",
    "    travel_data['Seats'] = 0\n",
    "\n",
    "    # Calculate the amount of seats by multiplying the number of coaches with the amount of seats per coach\n",
    "    # (source: Wikipedia) corresponding to the train type in the column 'VehicleType'\n",
    "    for q, i in enumerate(travel_data['VehicleType']):\n",
    "        travel_data.loc[q, 'Seats'] = travel_data.loc[q, 'TotalNumberOfCoaches'] * seats_per_vehicle_type[i]\n",
    "    \n",
    "    # Some DataFrames consist of 10 days, as we want to see only one week, some days will get removed from the\n",
    "    # DataFrame. This code will show trains in week 41 (October 7th to 13th)\n",
    "    travel_data['OperatingDay'] = pd.to_datetime(travel_data['OperatingDay'])\n",
    "    dates_to_exclude = pd.to_datetime(['2024-10-14', '2024-10-15', '2024-10-16'])\n",
    "    df_filtered = travel_data[~travel_data['OperatingDay'].isin(dates_to_exclude)]\n",
    "    travel_data = df_filtered.reset_index(drop=True)\n",
    "\n",
    "    # During construction works, some train services get alternative numbers, adding 20 or 70 in front of the\n",
    "    # original number (7903 -> 207903). As these are the same trajectories as the original route, the 20/70 \n",
    "    # will be removed\n",
    "    for i in range(len(travel_data)):\n",
    "        if travel_data.loc[i, 'JourneyNumber'] > 700000:\n",
    "            travel_data.loc[i, 'JourneyNumber'] -= 700000\n",
    "        if 200000 < travel_data.loc[i, 'JourneyNumber'] < 700000:\n",
    "            travel_data.loc[i, 'JourneyNumber'] -= 200000\n",
    "\n",
    "      \n",
    "    return travel_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_color(lower_limit, upper_limit, lower_color, upper_color, number):\n",
    "    '''Assign a color to a number based on where in the range of numbers it lies\n",
    "    \n",
    "    Args:\n",
    "        lower_limit (int): Minimum value of the range\n",
    "        upper_limit (int): Maximum value of the range\n",
    "        lower_color (tuple): RGB representation of the color for the minimum value\n",
    "        upper_color (tuple): RGB representation of the color for the maximum value\n",
    "        number (int): This is the number you want to interpolate\n",
    "\n",
    "    Output:\n",
    "        color (list): RGB representation of the color corresponding to the number\n",
    "    \n",
    "    '''\n",
    "    # Make sure the number is between the lower and upper limit\n",
    "    number = max(min(number, upper_limit), lower_limit)\n",
    "    \n",
    "    # Calculate the interpolation factor\n",
    "    factor = (number - lower_limit) / (upper_limit - lower_limit)\n",
    "    \n",
    "    # Interpolate each RGB component\n",
    "    interpolated_color = tuple(\n",
    "        int(lower_component + (upper_component - lower_component) * factor)\n",
    "        for lower_component, upper_component in zip(lower_color, upper_color)\n",
    "    )\n",
    "    \n",
    "    # Normalize the color for usage\n",
    "    color = [interpolated_color / 255.0 for interpolated_color in interpolated_color] \n",
    "\n",
    "    return color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seat_sorter(train_services_data, train_travel_data):\n",
    "    ''' Make a dictionary with the seats per train service\n",
    "\n",
    "    Args:\n",
    "        train_services_data (DataFrame): DataFrame with all train services in The Netherlands\n",
    "        train_travel_data (DataFrame): DataFrame with information about every journey including number of seats\n",
    "\n",
    "    Output:\n",
    "        dataframes_dict (dictionary): Dictionary with DataFrames per train service (in both directions)\n",
    "                                      containing the amount of seats on that train service    \n",
    "    '''\n",
    "    # Loading the CSV containing all train services with their stations in The Netherlands\n",
    "    train_services = pd.read_csv(train_services_data, delimiter = ';')\n",
    "    \n",
    "    # Creating an empty dictionary where the DataFrames will be stored\n",
    "    dataframes_dict = {}\n",
    "\n",
    "    # Creating the DataFrames for every train service in The Netherlands. This is done by splitting the\n",
    "    # strings with station abbreviations, and making every row in the DataFrame a trajectory between two \n",
    "    # stations. The seats column will remain empty.\n",
    "    for i in range(len(train_services)):\n",
    "        stations_per_service = train_services.loc[i,'String'].split(',')\n",
    "        df = pd.DataFrame({'From':[],'To':[],'Seats':[]})\n",
    "        for j in range(len(stations_per_service) - 1):\n",
    "            new_row = pd.DataFrame({'From': [stations_per_service[j]], 'To': [stations_per_service[j + 1]], 'Seats':[None]})\n",
    "            df = pd.concat([df, new_row], ignore_index=True)\n",
    "        dataframes_dict[train_services.loc[i,'Code']] = df\n",
    "\n",
    "        # This code makes DataFrames for the return journey, these DataFrames get a 1 at the end (900 -> 901)\n",
    "        stations_per_service = train_services.loc[i,'String'].split(',')\n",
    "        stations_per_service = stations_per_service[::-1]\n",
    "        df = pd.DataFrame({'From':[],'To':[],'Seats':[]})\n",
    "        for j in range(len(stations_per_service) - 1):\n",
    "            new_row = pd.DataFrame({'From': [stations_per_service[j]], 'To': [stations_per_service[j + 1]], 'Seats':[None]})\n",
    "            df = pd.concat([df, new_row], ignore_index=True)\n",
    "        dataframes_dict[train_services.loc[i,'Code'] + 1] = df\n",
    "\n",
    "    # Filling the seats column by checking the journey number in the train_travel_data. This journey number will be devided by 100\n",
    "    # and rounded down, to be multiplied by 100 again (946 -> 900). This number must correspond with a train service. If this number \n",
    "    # is even, it has to fill the even DataFrame of that train service (e.g. 900), if the number is odd, the odd DataFrame has to be\n",
    "    # filled (e.g. 901). If the row is still empty, the seats value (from train_travel_data) from a row will be stored in the\n",
    "    # corresponding DataFrame. If the row already has a value, the new amount of seats will be added on top of the old value.\n",
    "    for i in range(len(train_travel_data)):\n",
    "        # Checking if the number is odd, so the odd DataFrames will be filled\n",
    "        if train_travel_data.loc[i, 'JourneyNumber'] % 2 != 0:\n",
    "            # Obtaining the first 2/3 digits corresponding to the train service\n",
    "            service_begin = train_travel_data.loc[i, 'JourneyNumber']//100\n",
    "            start_value = 0\n",
    "            # Looping through the dictionary corresponding to the odd DataFrame corresponding to the train service\n",
    "            for j in range(len(dataframes_dict[service_begin*100+ 1])):\n",
    "                # Start with adding seats to the DataFrame if the begin station from the train_travel_data corresponds to the\n",
    "                # from-station in the newly made dictionaries.\n",
    "                if train_travel_data.loc[i, 'UserStopCodeBegin'].upper() == dataframes_dict[service_begin*100+ 1].loc[j, 'From'].upper():\n",
    "                    start_value = 1\n",
    "                \n",
    "                # If this value is true, seats get added to every row in that dictionary\n",
    "                if start_value == 1:\n",
    "                    if dataframes_dict[service_begin*100 + 1].loc[j, 'Seats'] == None:\n",
    "                        dataframes_dict[service_begin*100+ 1].loc[j, 'Seats'] = train_travel_data.loc[i, 'Seats']\n",
    "                    else:\n",
    "                        dataframes_dict[service_begin*100+ 1].loc[j, 'Seats'] += train_travel_data.loc[i, 'Seats']\n",
    "                \n",
    "                # If the end station has been reached (UserStopCodeEnd in the train_travel_data DataFrame) we stop adding the seats\n",
    "                # to the dictionaries\n",
    "                if train_travel_data.loc[i, 'UserStopCodeEnd'].upper() == dataframes_dict[service_begin*100+ 1].loc[j, 'To'].upper():\n",
    "                    break\n",
    "\n",
    "        else:\n",
    "            # Checking if the number is even, so the even DataFrames will be filled\n",
    "            service_begin = train_travel_data.loc[i, 'JourneyNumber']//100\n",
    "            start_value = 0\n",
    "            for j in range(len(dataframes_dict[service_begin*100])):\n",
    "                if train_travel_data.loc[i, 'UserStopCodeBegin'].upper() == dataframes_dict[service_begin*100].loc[j, 'From'].upper():\n",
    "                    start_value = 1\n",
    "                \n",
    "                if start_value == 1:\n",
    "                    if dataframes_dict[service_begin*100].loc[j, 'Seats'] == None:\n",
    "                        dataframes_dict[service_begin*100].loc[j, 'Seats'] = train_travel_data.loc[i, 'Seats']\n",
    "                    else:\n",
    "                        dataframes_dict[service_begin*100].loc[j, 'Seats'] += train_travel_data.loc[i, 'Seats']\n",
    "                \n",
    "                if train_travel_data.loc[i, 'UserStopCodeEnd'].upper() == dataframes_dict[service_begin*100].loc[j, 'To'].upper():\n",
    "                    break\n",
    "\n",
    "    return dataframes_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seats_per_trajectory(seats_dictionary):\n",
    "    ''' Multiple services use the same tracks, this function adds seats on the same trajectory from different services.\n",
    "\n",
    "    Args:\n",
    "        seats_dictionary (dict): Dictionary with DataFrames per train service (in both directions)\n",
    "                                 containint the amount of seats on that train service\n",
    "    \n",
    "    Output:\n",
    "        seats_per_trajectory (DataFrame): DataFrame with all trajectories and the amount of seats\n",
    "    '''\n",
    "    \n",
    "    # Creating a new DataFrame for storing the data of the seats\n",
    "    seats_per_trajectory = pd.DataFrame({'From':[],'To':[],'Seats':[]})\n",
    "\n",
    "    # Looping through the DataFrames in the dictionary. For each row in each DataFrame in the dictionary a check will \n",
    "    # be done if the combination of stations (begin/end) already exists in the newly made DataFrame. If not, this combination\n",
    "    # will be added. When the row already exists, the number of seats will be added to the corresponding trajectory\n",
    "    for i in seats_dictionary.keys():\n",
    "        train_service_df = seats_dictionary[i]\n",
    "        row_value = 0\n",
    "        existence_checker = 0\n",
    "        for j in range(len(train_service_df)):\n",
    "            # If there are no seats in the row that is being checked, this iteration will be skipped\n",
    "            if train_service_df.loc[j,'Seats'] == None:\n",
    "                continue\n",
    "\n",
    "            # Otherwise, a loop will be started through all DataFrames in the dictionary\n",
    "            for k in range(len(seats_per_trajectory)):\n",
    "                # If the tractory is already existing, the existence_checker will be set to 1 and the\n",
    "                # row_value is equal to the iteration in this loop\n",
    "                if train_service_df.loc[j,'From'].upper() == seats_per_trajectory.loc[k, 'From'].upper() \\\n",
    "                   and train_service_df.loc[j,'To'].upper() == seats_per_trajectory.loc[k, 'To'].upper():\n",
    "                    existence_checker = 1\n",
    "                    row_value = k\n",
    "                    break\n",
    "                # Else, if the trajectory is driven in the other direction, the same statements will be True\n",
    "                elif train_service_df.loc[j,'To'].upper() == seats_per_trajectory.loc[k, 'From'].upper() \\\n",
    "                   and train_service_df.loc[j,'From'].upper() == seats_per_trajectory.loc[k, 'To'].upper():\n",
    "                    existence_checker = 1\n",
    "                    row_value = k\n",
    "                    break\n",
    "            \n",
    "            # If the row already exists, the number of seats from the row_value will be added to the already found seats\n",
    "            # and the existence_checker will be reset to zero\n",
    "            if existence_checker == 1:\n",
    "                seats_per_trajectory.loc[row_value, 'Seats'] += train_service_df.loc[j,'Seats']\n",
    "                existence_checker = 0\n",
    "            # When the row does not exist yet, a new row with trajectory has to be made including its seats\n",
    "            else:\n",
    "                new_row = pd.DataFrame({'From': [train_service_df.loc[j,'From'].upper()], \n",
    "                                        'To': [train_service_df.loc[j,'To'].upper()], 'Seats':[train_service_df.loc[j,'Seats']]})\n",
    "                seats_per_trajectory = pd.concat([seats_per_trajectory, new_row], ignore_index=True)\n",
    "    return seats_per_trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geometry_maker(trajectory_list):\n",
    "    ''' This function retrieves geometry data from the NS API for each trajectory.\n",
    "        Please note: To run this function, you need an subscription key from the NS API.\n",
    "                     For more information, see: https://www.ns.nl/reisinformatie/ns-api\n",
    "\n",
    "    Args:\n",
    "        trajectory_list (DataFrame): A DataFrame with at least the columns \"From\" and \"To\" from which the geometry will be retrieved\n",
    "\n",
    "    Output:\n",
    "        trajectory_and_geometry (GeoDataFrame): A DataFrame with the geometries per trajactory added to the existing input DataFrame\n",
    "    '''    \n",
    "    # Input for the subscription key before starting the loop\n",
    "    subscription_key = input('Please enter your subscription key: ')\n",
    "\n",
    "    geometry_data = []\n",
    "\n",
    "    for i in range(len(trajectory_list)):\n",
    "        while True:\n",
    "            try:\n",
    "                # Make the API request and retrieve the geodata\n",
    "                geodata = api_request(f'{trajectory_list[\"From\"][i]},{trajectory_list[\"To\"][i]}', subscription_key)\n",
    "                \n",
    "                # If the API request is successful, add geometry data and break out of the loop\n",
    "                if geodata is not None:\n",
    "                    geometry_data.append(geodata['geometry'].iloc[0])\n",
    "                    print(f'{i+1}/{len(trajectory_list)}', end=\"\\r\")\n",
    "                    break\n",
    "                else:\n",
    "                    # If the API fails, prompt for a new subscription key\n",
    "                    subscription_key = input('Invalid subscription key. Please enter a new subscription key: ')\n",
    "            # If another error occurs, ask again for the subscription key\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred: {e}\")\n",
    "                subscription_key = input('Error occurred. Please enter a new subscription key: ')\n",
    "\n",
    "    trajectory_list['geometry'] = geometry_data\n",
    "    trajectory_and_geometry = gpd.GeoDataFrame(trajectory_list, geometry='geometry')\n",
    "    return trajectory_and_geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All input data for the map types that will be made\n",
    "# Map type 1: Per day/Complete week of all operators per train type\n",
    "# Map type 2: Per operator/All operators of the complete week per train type\n",
    "\n",
    "# Train series seperates by train type: intercity/sprinter\n",
    "intercities = [1000, 1100, 11400, 11600, 11700, 12600, 1400, 1500, 600, 1700, 17900, 1800, \n",
    "               200, 2000, 2100, 21400, 21500, 2200, 22200, 22400, 2300, 23400, 240, 2400, 24400, \n",
    "               2600, 2800, 2900, 3000, 3100, 3200, 3500, 3600, 32790, 3700, 37300, 37900, 3900, \n",
    "               4500, 500, 600, 700, 800, 900, 9200]\n",
    "sprinters = [13300, 13800, 14300, 14900, 15400, 16400, 17800, 18900, 20100, 20200, 25400, 30400, \n",
    "             30700, 30800, 30900, 31000, 31100, 31200, 31300, 31400, 32000, 32200, 32300, 32400, \n",
    "             32500, 32700, 3300, 36900, 37000, 37100, 37200, 37400, 37500, 37600, 37700, 37800, \n",
    "             3800, 38000, 4000, 4300, 4400, 4600, 4800, 4900, 5000, 5100, 5200, 5400, 5500, 5600, \n",
    "             5700, 5800, 5900, 6000, 6100, 6200, 6300, 6400, 6600, 6700, 6800, 6900, 7000, 7100, \n",
    "             7200, 7300, 7400, 7500, 7600, 7900, 8000, 8100, 8500, 8600, 8700, 8800, 8900, 9000]\n",
    "train_options = ['intercities', 'sprinters', 'all']\n",
    "\n",
    "# A dictionary for every train type with the corresponding number of seats\n",
    "seats_per_vehicle_type = {\"VIRM\": 100, \"DDZ\": 100, \"FLIRT FFF\": 53, \"ICM\": 75,\n",
    "                      \"ICNG25\": 52, \"SLT\": 54, \"SNG\": 50, \"SW7-25KV\": 48,\n",
    "                      \"SW9-25KV\": 48, \"GTW\": 45, \"Flirt\": 57, \"FLIRT\": 57,\n",
    "                      \"Lint\": 65, \"WINK\": 153}\n",
    "\n",
    "# Dates used in this model (week 41)\n",
    "dates = [['2024-10-07', '2024-10-08', '2024-10-09', '2024-10-10', '2024-10-11', '2024-10-12', '2024-10-13']]\n",
    "\n",
    "# Since we made also odd train services in the function seat_sorter, we also need the odd \n",
    "# values in the above made lists\n",
    "intercities_plus_one = [x + 1 for x in intercities] \n",
    "intercities = intercities + intercities_plus_one       \n",
    "sprinters_plus_one = [x + 1 for x in sprinters] \n",
    "sprinters = sprinters + sprinters_plus_one  \n",
    "\n",
    "# Different operators found in The Netherlands\n",
    "operators = ['Keolis', 'Arriva', 'NS', 'Qbuzz']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, the new DataFrames will be made with the extra column containing the seats for every operator\n",
    "for operator in operators:\n",
    "    operator_csv = travel_data([operator], seats_per_vehicle_type)\n",
    "    operator_csv.to_csv(f\"TravelData{operator}.csv\")\n",
    "\n",
    "# and also for all operators combined\n",
    "operators_csv = travel_data(operators, seats_per_vehicle_type)\n",
    "operators_csv.to_csv(f\"TravelData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTPError: 401 - Unauthorized\n",
      "HTTPError: 401 - Unauthorized\n",
      "HTTPError: 401 - Unauthorized\n",
      "HTTPError: 401 - Unauthorized\n",
      "HTTPError: 401 - Unauthorized\n",
      "HTTPError: 401 - Unauthorized\n",
      "HTTPError: 401 - Unauthorized\n",
      "HTTPError: 401 - Unauthorized\n",
      "HTTPError: 401 - Unauthorized\n",
      "HTTPError: 401 - Unauthorized\n",
      "HTTPError: 401 - Unauthorized\n",
      "HTTPError: 401 - Unauthorized\n",
      "HTTPError: 401 - Unauthorized\n",
      "HTTPError: 401 - Unauthorized\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 25\u001b[0m\n\u001b[0;32m     23\u001b[0m     SortedSeats1 \u001b[38;5;241m=\u001b[39m SortedSeats\n\u001b[0;32m     24\u001b[0m SeatsPerTrajectory \u001b[38;5;241m=\u001b[39m seats_per_trajectory(SortedSeats1)\n\u001b[1;32m---> 25\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mgeometry_maker\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSeatsPerTrajectory\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m#volgorde zo aanpassen dat de hogere waardes altijd later worden geplot en dus over de lagere waardes heen plotten\u001b[39;00m\n\u001b[0;32m     27\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSeats\u001b[39m\u001b[38;5;124m'\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mreset_index()\n",
      "Cell \u001b[1;32mIn[20], line 30\u001b[0m, in \u001b[0;36mgeometry_maker\u001b[1;34m(trajectory_list)\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     29\u001b[0m         \u001b[38;5;66;03m# If the API fails, prompt for a new subscription key\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m         subscription_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mInvalid subscription key. Please enter a new subscription key: \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# If another error occurs, ask again for the subscription key\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\niels\\anaconda3\\envs\\TIL6022\\Lib\\site-packages\\ipykernel\\kernelbase.py:1282\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m   1280\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1281\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[1;32m-> 1282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1283\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1284\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1285\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1287\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\niels\\anaconda3\\envs\\TIL6022\\Lib\\site-packages\\ipykernel\\kernelbase.py:1325\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m   1322\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1323\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[0;32m   1324\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1325\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1326\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "# Making of map type 1 (24 Plot-data files)\n",
    "#   - All operators\n",
    "#   - 7 of every seperate day and 1 of the complete week\n",
    "#   - Both train types, only sprinters, only intercities\n",
    "# All maps get the same color scale\n",
    "\n",
    "dates = [['2024-10-07', '2024-10-08', '2024-10-09', '2024-10-10', '2024-10-11', '2024-10-12', '2024-10-13'],['2024-10-07'], ['2024-10-08'], ['2024-10-09'], ['2024-10-10'], ['2024-10-11'], ['2024-10-12'], ['2024-10-13']]\n",
    "\n",
    "for i in range(len(dates)):\n",
    "    print(f'{i+1}/{len(dates)}', end=\"\\r\")\n",
    "    travel_data = pd.read_csv('TravelData.csv')\n",
    "    dates_to_include = dates[i]\n",
    "    df_filtered = travel_data[travel_data['OperatingDay'].isin(dates_to_include)]\n",
    "    travel_data = df_filtered.reset_index(drop=True)\n",
    "    SortedSeats = seat_sorter('TrainServices.csv',travel_data)\n",
    "    for q, j in enumerate(train_options):\n",
    "        print(f'{q+1}/{len(train_options)}', end=\"\\r\")\n",
    "        if j == 'intercities':\n",
    "            SortedSeats1 = {k: v for k, v in SortedSeats.items() if k in intercities}\n",
    "        if j == 'sprinters':\n",
    "            SortedSeats1 = {k: v for k, v in SortedSeats.items() if k in sprinters}\n",
    "        elif j == 'all':\n",
    "            SortedSeats1 = SortedSeats\n",
    "        SeatsPerTrajectory = seats_per_trajectory(SortedSeats1)\n",
    "        df = geometry_maker(SeatsPerTrajectory)\n",
    "        #volgorde zo aanpassen dat de hogere waardes altijd later worden geplot en dus over de lagere waardes heen plotten\n",
    "        df = df.sort_values(by='Seats', ascending=True).reset_index()\n",
    "        # kleuren assignen en toevoegen aan de geopanda\n",
    "        df['color'] = '0'\n",
    "        for h in range(len(df)):\n",
    "            df.loc[h, 'color'] = str(interpolate_color(df['Seats'].min(), df['Seats'].max(), (255,255,0), (255,0,0), df.loc[h, 'Seats']))\n",
    "        if len(dates[i]) > 2:\n",
    "            df.to_csv(f'PlotDataWeek{train_options[q]}.csv')\n",
    "        else:\n",
    "            df.to_csv(f'PlotData{dates[i][0]}{train_options[q]}.csv')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/10\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thijs\\AppData\\Local\\Temp\\ipykernel_48224\\29126510.py:36: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[1.0, 1.0, 0.0]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[h, 'color'] = str(interpolate_color(df['Seats'].min(), df['Seats'].max(), (255,255,0), (255,0,0), df.loc[h, 'Seats']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thijs\\AppData\\Local\\Temp\\ipykernel_48224\\29126510.py:36: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[1.0, 1.0, 0.0]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[h, 'color'] = str(interpolate_color(df['Seats'].min(), df['Seats'].max(), (255,255,0), (255,0,0), df.loc[h, 'Seats']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/419\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thijs\\AppData\\Local\\Temp\\ipykernel_48224\\29126510.py:36: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[1.0, 1.0, 0.0]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[h, 'color'] = str(interpolate_color(df['Seats'].min(), df['Seats'].max(), (255,255,0), (255,0,0), df.loc[h, 'Seats']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/315\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thijs\\AppData\\Local\\Temp\\ipykernel_48224\\29126510.py:36: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[1.0, 1.0, 0.0]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[h, 'color'] = str(interpolate_color(df['Seats'].min(), df['Seats'].max(), (255,255,0), (255,0,0), df.loc[h, 'Seats']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thijs\\AppData\\Local\\Temp\\ipykernel_48224\\29126510.py:36: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[1.0, 1.0, 0.0]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[h, 'color'] = str(interpolate_color(df['Seats'].min(), df['Seats'].max(), (255,255,0), (255,0,0), df.loc[h, 'Seats']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thijs\\AppData\\Local\\Temp\\ipykernel_48224\\29126510.py:36: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[1.0, 1.0, 0.0]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[h, 'color'] = str(interpolate_color(df['Seats'].min(), df['Seats'].max(), (255,255,0), (255,0,0), df.loc[h, 'Seats']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256/256\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thijs\\AppData\\Local\\Temp\\ipykernel_48224\\29126510.py:36: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[1.0, 1.0, 0.0]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[h, 'color'] = str(interpolate_color(df['Seats'].min(), df['Seats'].max(), (255,255,0), (255,0,0), df.loc[h, 'Seats']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3/240\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thijs\\AppData\\Local\\Temp\\ipykernel_48224\\29126510.py:36: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[1.0, 1.0, 0.0]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[h, 'color'] = str(interpolate_color(df['Seats'].min(), df['Seats'].max(), (255,255,0), (255,0,0), df.loc[h, 'Seats']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4/282\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thijs\\AppData\\Local\\Temp\\ipykernel_48224\\29126510.py:36: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[1.0, 1.0, 0.0]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[h, 'color'] = str(interpolate_color(df['Seats'].min(), df['Seats'].max(), (255,255,0), (255,0,0), df.loc[h, 'Seats']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/11\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thijs\\AppData\\Local\\Temp\\ipykernel_48224\\29126510.py:36: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[1.0, 1.0, 0.0]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[h, 'color'] = str(interpolate_color(df['Seats'].min(), df['Seats'].max(), (255,255,0), (255,0,0), df.loc[h, 'Seats']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thijs\\AppData\\Local\\Temp\\ipykernel_48224\\29126510.py:36: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[1.0, 1.0, 0.0]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[h, 'color'] = str(interpolate_color(df['Seats'].min(), df['Seats'].max(), (255,255,0), (255,0,0), df.loc[h, 'Seats']))\n"
     ]
    }
   ],
   "source": [
    "# Making of map type 2 (15 Plot-data files)\n",
    "# - Only complete week\n",
    "# - 4 of every seperate operators, 1 for all operators\n",
    "# - Both train types, only sprinters, only intercities\n",
    "# All maps get another color scale\n",
    "\n",
    "for i in range(len(operators)):\n",
    "    print(f'{i+1}/{len(operators)}', end=\"\\r\")\n",
    "    travel_data = pd.read_csv(f'TravelData{operators[i]}.csv')\n",
    "    datestoinclude = ['2024-10-07', '2024-10-08', '2024-10-09', '2024-10-10', '2024-10-11', '2024-10-12', '2024-10-13']\n",
    "    df_filtered = travel_data[travel_data['OperatingDay'].isin(datestoinclude)]\n",
    "    travel_data = df_filtered.reset_index(drop=True)\n",
    "    SortedSeats = seat_sorter('TrainServices.csv',travel_data)\n",
    "    for q, j in enumerate(train_options):\n",
    "        print(f'{q+1}/{len(train_options)}', end=\"\\r\")\n",
    "        if j == 'intercities':\n",
    "            SortedSeats1 = {k: v for k, v in SortedSeats.items() if k in intercities}\n",
    "        if j == 'sprinters':\n",
    "            SortedSeats1 = {k: v for k, v in SortedSeats.items() if k in sprinters}\n",
    "        elif j == 'all':\n",
    "            SortedSeats1 = SortedSeats\n",
    "        SeatsPerTrajectory = seats_per_trajectory(SortedSeats1)\n",
    "        df = geometry_maker(SeatsPerTrajectory)\n",
    "        #volgorde zo aanpassen dat de hogere waardes altijd later worden geplot en dus over de lagere waardes heen plotten\n",
    "        df = df.sort_values(by='Seats', ascending=True).reset_index()\n",
    "        # kleuren assignen en toevoegen aan de geopanda\n",
    "        df['color'] = '0'\n",
    "        for h in range(len(df)):\n",
    "            df.loc[h, 'color'] = str(interpolate_color(df['Seats'].min(), df['Seats'].max(), (255,255,0), (255,0,0), df.loc[h, 'Seats']))\n",
    "        df.to_csv(f'PlotDataWeek{operators[i]}{train_options[q]}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TIL6022",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
